{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmassaron/ml4dummies_3ed/blob/main/ML4D3E_17_scoring_opinions_and_sentiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rcuIDtFeBxuE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Jeu_Gda82qBS"
      },
      "outputs": [],
      "source": [
        "text_1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "text_2 = \"My dog is quick and can jump over fences.\"\n",
        "text_3 = \\\n",
        "      \"Your dog is so lazy that it sleeps all the day.\"\n",
        "corpus = [text_1, text_2, text_3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyxWKsN12p-e",
        "outputId": "a009211a-011d-4546-fcdf-c37dc4901ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1]\n",
            " [1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import (\n",
        "    CountVectorizer)\n",
        "\n",
        "vectorizer = CountVectorizer(binary=True,\n",
        "                             lowercase=False)\n",
        "vectorizer.fit(corpus)\n",
        "vectorized_text = vectorizer.transform(corpus)\n",
        "print(vectorized_text.todense())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMzN7_SL2p7x",
        "outputId": "c4a2a6e0-8dff-4d85-a9db-d1d403518370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'The': 1, 'quick': 17, 'brown': 5, 'fox': 10, 'jumps': 14, 'over': 16, 'the': 21, 'lazy': 15, 'dog': 8, 'My': 0, 'is': 11, 'and': 4, 'can': 6, 'jump': 13, 'fences': 9, 'Your': 2, 'so': 19, 'that': 20, 'it': 12, 'sleeps': 18, 'all': 3, 'day': 7}\n"
          ]
        }
      ],
      "source": [
        "print(vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENBEFrH82p44",
        "outputId": "086eebd6-5f00-48a1-bfe3-444f2cb3a930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 1 1 1 0 0 2 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "text_4 = \\\n",
        "    \"A black dog just passed by but my dog is brown.\"\n",
        "corpus.append(text_4)\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "vectorized_text = vectorizer.transform(corpus)\n",
        "print(vectorized_text.todense()[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEw2syiX2p10",
        "outputId": "b3620a23-97a2-48d6-804c-df0417398f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brown  : 0.095\n",
            "dog    : 0.126\n",
            "my     : 0.095\n",
            "is     : 0.077\n",
            "black  : 0.121\n",
            "just   : 0.121\n",
            "passed : 0.121\n",
            "by     : 0.121\n",
            "but    : 0.121\n",
            "\n",
            "Summed values of a phrase: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import (\n",
        "    TfidfTransformer)\n",
        "\n",
        "tfidf = TfidfTransformer(norm=\"l1\")\n",
        "tfidf_mtx = tfidf.fit_transform(vectorized_text)\n",
        "\n",
        "phrase = 3 # choose a number from 0 to 3\n",
        "\n",
        "total = 0\n",
        "for word in vectorizer.vocabulary_:\n",
        "    pos = vectorizer.vocabulary_[word]\n",
        "    value = list(tfidf_mtx.toarray()[phrase])[pos]\n",
        "    if value !=0.0:\n",
        "        print(f\"{word:7s}: {value:0.3f}\")\n",
        "        total += value\n",
        "print(f\"\\nSummed values of a phrase: {total:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmfJjVqz2py5",
        "outputId": "58afc81f-7365-4f16-95cc-4bd7c917682d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the quick': 30, 'quick brown': 24, 'brown fox': 3, 'fox jumps': 9, 'jumps over': 15, 'over the': 21, 'the lazy': 29, 'lazy dog': 17, 'my dog': 19, 'dog is': 7, 'is quick': 11, 'quick and': 23, 'and can': 1, 'can jump': 6, 'jump over': 14, 'over fences': 20, 'your dog': 31, 'is so': 12, 'so lazy': 26, 'lazy that': 18, 'that it': 27, 'it sleeps': 13, 'sleeps all': 25, 'all the': 0, 'the day': 28, 'black dog': 2, 'dog just': 8, 'just passed': 16, 'passed by': 22, 'by but': 5, 'but my': 4, 'is brown': 10}\n"
          ]
        }
      ],
      "source": [
        "bigrams = CountVectorizer(ngram_range=(2, 2))\n",
        "print(bigrams.fit(corpus).vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hg8Gw-B4rxH",
        "outputId": "afe68265-807f-4a6a-eb1e-ca3ab3da4990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ2eCjMe2pv6",
        "outputId": "a5a382dc-9241-4c8e-eff2-637adc21d0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['love' 'sam' 'swim' 'time']\n",
            "[[1 0 1 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import (\n",
        "    CountVectorizer)\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "def stem_tokens(tokens, stemmer):\n",
        "    stemmed = []\n",
        "    for item in tokens:\n",
        "        stemmed.append(stemmer.stem(item))\n",
        "    return stemmed\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [token for token in tokens\n",
        "              if token not in stop_words]\n",
        "    stems = stem_tokens(tokens, stemmer)\n",
        "    return stems\n",
        "\n",
        "docs = [\"Sam loves swimming so he swims all the time\"]\n",
        "vect = CountVectorizer(tokenizer=tokenize)\n",
        "vec = vect.fit(docs)\n",
        "\n",
        "sentence1 = vec.transform(\n",
        "    [\"George loves swimming too! \"])\n",
        "\n",
        "print(vec.get_feature_names_out())\n",
        "print(sentence1.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EQ_5kzKCk72Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "repository = \\\n",
        "    \"https://github.com/lmassaron/ml4dummies_3ed/\"\n",
        "release = \"releases/download/v1.0/\"\n",
        "filename = repository + release + \"imdb_50k.csv\"\n",
        "reviews = pd.read_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "fIFkxfpklXsa",
        "outputId": "c91ec8b6-8059-4619-91d1-3109dcf0add6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "1    25000\n",
              "0    25000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "reviews.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwJ1fhqBlbfi",
        "outputId": "b9cff492-36cb-4430-ae47-e314e166ebb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey guy, this movies is everything about choices. All the times in your life you must pick something or it just pass away... And this movie prove that! Of course, life in fact is not like a beautiful picture as this movie shows... it not shows indeed but some may figure that. I'm trying to say it's full of pain, love and deep lessons of live. Aaron, the Mormon missionary is the real shepherd digging out the thing beautiful deep inside Chisthian, the skin feeling guy...<br /><br />It's a great end and you do always believe in fate because it will surprise you in a turn or in other of your live like Latter Days...<br /><br />Big deal watch it!!!\n"
          ]
        }
      ],
      "source": [
        "print(reviews.review.sample(1).values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tjeuNkCwTW7",
        "outputId": "93a8184b-ae6c-487d-f42c-e03513faf08c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 30000\n",
            "Validation size: 10000\n",
            "Test size: 10000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, temp = train_test_split(\n",
        "    reviews, test_size=0.4, random_state=0)\n",
        "valid, test = train_test_split(\n",
        "    temp, test_size=0.5, random_state=0)\n",
        "\n",
        "print(f\"Train size: {len(train)}\")\n",
        "print(f\"Validation size: {len(valid)}\")\n",
        "print(f\"Test size: {len(test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "voEKf4_sPEDn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "os.environ[\"HF_HUB_DISABLE_IMPLICIT_TOKEN\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FD0Tpc3AH1zR"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "maxlen = 256\n",
        "vocab_size_limit = 10000\n",
        "\n",
        "text_vectorization = keras.layers.TextVectorization(\n",
        "    max_tokens=vocab_size_limit,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=maxlen,\n",
        "    pad_to_max_tokens=True)\n",
        "\n",
        "text_vectorization.adapt(train.review.values)\n",
        "\n",
        "def vectorize_text_data(df, vectorizer):\n",
        "    sequences = vectorizer(df.review.values)\n",
        "    return sequences, df.sentiment.values\n",
        "\n",
        "X, y = vectorize_text_data(train, text_vectorization)\n",
        "Xv, yv = vectorize_text_data(valid, text_vectorization)\n",
        "Xt, yt = vectorize_text_data(test, text_vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WiZD6AQl9hul",
        "outputId": "aa110f2d-f3fa-4442-9c44-2754608153e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m640,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m24,832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m689,729\u001b[0m (2.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">689,729</span> (2.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m689,729\u001b[0m (2.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">689,729</span> (2.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "keras.utils.set_random_seed(0)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "vocab_size = text_vectorization.vocabulary_size()\n",
        "embedding_dim = 64\n",
        "\n",
        "model.add(keras.layers.Input(shape=(maxlen,)))\n",
        "model.add(keras.layers.Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embedding_dim))\n",
        "model.add(keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(32, return_sequences=True)))\n",
        "model.add(keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(32, return_sequences=False)))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EcLSgI9_PYu",
        "outputId": "05d776dd-9234-4ead-8879-0210bf1bc314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 35ms/step - accuracy: 0.6468 - loss: 0.6230 - val_accuracy: 0.8466 - val_loss: 0.3587\n",
            "Epoch 2/2\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 34ms/step - accuracy: 0.8769 - loss: 0.3110 - val_accuracy: 0.8802 - val_loss: 0.2800\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X, y, epochs=2, batch_size=8,\n",
        "                    validation_data=(Xv, yv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDL0Hb2jQqMX",
        "outputId": "3f073bc3-1a02-4f69-a6d7-12f4d747d0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step\n",
            "Accuracy on test set: 0.8828\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions = (model.predict(Xt)>=0.5).astype(int)\n",
        "test_accuracy = accuracy_score(yt, predictions)\n",
        "print(f\"Accuracy on test set: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I6mznh7_Wxs",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"answerdotai/ModernBERT-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"],\n",
        "                     padding=\"max_length\",\n",
        "                     truncation=True,\n",
        "                     max_length=256)\n",
        "\n",
        "def tokenize_dataset(data):\n",
        "  data_dict = {'text': data['review'].values,\n",
        "               'labels': data['sentiment'].values}\n",
        "  dataset = Dataset.from_dict(data_dict)\n",
        "  return dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_train_dataset = tokenize_dataset(train)\n",
        "tokenized_valid_dataset = tokenize_dataset(valid)\n",
        "tokenized_test_dataset = tokenize_dataset(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXtNaqUw_YTP"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification as AutoModel)\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name,\n",
        "                                  num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Re5rhFRaQO3M",
        "outputId": "a1259943-f8d2-409a-9346-33a6002d7532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0817 18:08:02.287000 1100 torch/_inductor/utils.py:1137] [1/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3750/3750 29:47, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.339900</td>\n",
              "      <td>0.193214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.263900</td>\n",
              "      <td>0.195235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.237900</td>\n",
              "      <td>0.206862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.207635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.228900</td>\n",
              "      <td>0.208621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.204100</td>\n",
              "      <td>0.198057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.186400</td>\n",
              "      <td>0.196846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\",\n",
        "    eval_strategy=\"steps\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_valid_dataset)\n",
        "\n",
        "train_result = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VGbRmXnjco5T",
        "outputId": "191b66b7-bd4e-4d43-d9b9-6b6f0f717f3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.9427\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions = trainer.predict(tokenized_test_dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions,\n",
        "                             axis=1)\n",
        "test_accuracy = accuracy_score(test['sentiment'].values,\n",
        "                               predicted_labels)\n",
        "print(f\"Accuracy on test set: {test_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}